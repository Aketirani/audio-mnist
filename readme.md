# Gender Recognition By Voice Analysis ğŸ—£ï¸ğŸ™ï¸
This project leverages acoustic features from voice recordings to predict the speaker's gender. Utilizing a large dataset and the XGBoost machine learning library, this project aims to build a high-accuracy model for gender classification based on voice characteristics.

![ANC Gif](images/gender.gif)

### Table of Contents ğŸ“–
- [Project Overview](#project-overview) ğŸ”
- [Structure](#structure) ğŸ“‚
- [Data Summary](#data-summary) ğŸ²
- [Dataset](#dataset) ğŸ“Š
- [Model Selection](#model-selection) ğŸ§°
- [Model Architecture](#model-architecture) âš™ï¸
- [Model Features](#model-features) ğŸ§¬
- [Model Performance](#model-performance) ğŸ¯
- [PostgreSQL Integration](#postgresql-integration) ğŸ›¢ï¸
- [Conclusion](#conclusion) ğŸ’¡
- [Requirements](#requirements) ğŸ“‘
- [Execution](#execution) ğŸƒâ€â™‚ï¸
- [Flowchart](#flowchart) ğŸ”
- [Unit Tests](#unit-tests) ğŸ§ª
- [Developer](#developer) ğŸ‘¤

### Project Overview
Voice recordings provide insights into various speaker attributes, including content, emotional state, gender, and identity. This project focuses on gender recognition, aiming to develop a model that accurately identifies gender-specific patterns in voice recordings through acoustic features.

### Structure
```
â”Œâ”€â”€ audio                       <-- Audio Folder
|   â””â”€â”€ recordings              <-- Recordings Folder
|       â””â”€â”€ *.wav               <-- Audio Recordings
|   â””â”€â”€ audioMNIST_meta.txt     <-- Meta Information
|
â”œâ”€â”€ config                      <-- Configuration Folder
|   â””â”€â”€ *.yaml                  <-- Configuration Files
|
â”œâ”€â”€ data                        <-- Data Folder
|   â””â”€â”€ *.csv                   <-- Data Files
|
â”œâ”€â”€ html                        <-- HTML Folder
|   â””â”€â”€ *.html                  <-- HTML Files
|
â”œâ”€â”€ images                      <-- Image Folder
|   â””â”€â”€ *.png                   <-- Image Files
|
â”œâ”€â”€ logs                        <-- Log Folder
|   â””â”€â”€ *.log                   <-- Log Files
|
â”œâ”€â”€ parameters                  <-- Parameters Folder
|   â””â”€â”€ *.yaml                  <-- Model Parameters
|
â”œâ”€â”€ plots                       <-- Plots Folder
|   â””â”€â”€ *.png                   <-- Plots
|
â”œâ”€â”€ results                     <-- Results Folder
|   â””â”€â”€ *.yaml                  <-- Model Results
|
â”œâ”€â”€ src                         <-- Source Folder
|   â””â”€â”€ *.py                    <-- Source Files
|
â”œâ”€â”€ test                        <-- Test Folder
|   â””â”€â”€ *.py                    <-- Unit Tests
|
â”œâ”€â”€ text                        <-- Text Folder
|   â””â”€â”€ *.txt                   <-- Text Files
|
â”œâ”€â”€ .gitignore                  <-- Git Ignore Configuration
|
â”œâ”€â”€ .pre-commit-config.yaml     <-- Pre-Commit Configuration
|
â”œâ”€â”€ audio_mnist.py              <-- Main Python Script
|
â”œâ”€â”€ audio_mnist.sh              <-- Main Shell Script
|
â”œâ”€â”€ flowchart.wsd               <-- Pipeline Flowchart
|
â”œâ”€â”€ gui.py                      <-- GUI Python Script
|
â”œâ”€â”€ readme.md                   <-- You Are Here
|
â””â”€â”€ requirements.txt            <-- Package Requirements
```

### Dataset
This project utilizes a comprehensive [dataset](https://www.kaggle.com/datasets/primaryobjects/voicegender) with 30,000 spoken digits (0-9) audio samples from 60 distinct speakers. Each speaker's directory contains their audio recordings and a meta-information file.

### Data Summary
Explore a detailed data profiling report by opening the `html/profiling_report.html` file in your web browser. This report offers statistical insights, distribution plots, and a comprehensive overview of the dataset's characteristics.

### Model Selection
The choice of [XGBoost](https://xgboost.readthedocs.io/en/stable/) (eXtreme Gradient Boosting) is based on its efficiency and scalability, especially for large datasets and complex models. It effectively handles missing values, categorical variables, and high-dimensional data, making it well-suited for this project. XGBoost's regularization techniques help prevent overfitting and enhance model generalization.

### Model Architecture
A gradient boosting tree ensemble model within the XGBoost framework is employed. This model synergizes predictions from multiple decision trees to determine the speaker's gender. Fine-tuning is achieved through key parameters, allowing for optimal performance.

The model uses the following key parameters:
| Parameter       | Description          |
|-----------------|----------------------|
| `learning_rate` | Learning Rate        |
| `max_depth`     | Max Depth Of Tree    |
| `n_estimators`  | Number Of Estimators |
| `objective`     | Objective Function   |
| `tree_method`   | Tree Method          |

### Model Features
The model uses various statistical features from both time-domain and frequency-domain data of the audio samples. These features are crucial for training the model to recognize gender-specific patterns.

These features include:
| Feature     | Description        |
|-------------|--------------------|
| `mean`      | Mean               |
| `std`       | Standard Deviation |
| `med`       | Median             |
| `min`       | Minimum            |
| `q25`       | 25th Percentiles   |
| `q75`       | 75th Percentiles   |
| `max`       | Maximum            |
| `skew`      | Skewness           |
| `kurt`      | Kurtosis           |
| `zeroxrate` | Zero Crossing Rate |
| `entropy`   | Entropy            |
| `sfm`       | Spectral Flatness  |
| `cent`      | Frequency Centroid |

### Model Performance
The model has achieved a promising accuracy rate of `97.83%` on the test dataset, showcasing its potential in gender recognition through voice analysis.

### PostgreSQL Integration
PostgreSQL integration enhances data management capabilities. By utilizing [PostgreSQL](https://www.postgresql.org), an open-source object-relational database system, we ensure scalability, robustness, and efficient data storage and retrieval. Store connection details in the `config/postgres.yaml` file and perform database operations using SQL queries.

### Conclusion
This project exemplifies the application of machine learning in voice and speech analysis, showcasing the potential to discern gender through acoustic features.

### Requirements
Execute `pip install -r requirements.txt` to install the required libraries.

### Execution
Execute `audiomnist.sh` to initiate the entire pipeline.

Following arguments can be specified:
| Argument              | Description                               |
|-----------------------|-------------------------------------------|
| `-c`, `--cfg_file`    | Path to the configuration file            |
| `-y`, `--pgs_file`    | Path to the PostgreSQL configuration file |
| `-d`, `--data_prep`   | Execute the data preparation step         |
| `-f`, `--feat_eng`    | Execute the feature engineering step      |
| `-s`, `--data_split`  | Execute the data splitting step           |
| `-u`, `--model_tune`  | Execute the model tuning step             |
| `-t`, `--model_train` | Execute the model training step           |
| `-p`, `--model_pred`  | Execute the model prediction step         |
| `-q`, `--save_sql`    | Execute the save to postgreSQL step       |

### Flowchart
![AudioMNIST Gif](images/flowchart.svg)

### Unit Tests
Execute `python -m unittest discover test` to run all unit tests, ensuring the reliability of the code base.

### Developer
Execute `python -m pre_commit run --all-files` to ensure code quality and formatting checks.
